### Single-stage fusion methods.
• MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird's Eye View Maps / [paper](https://arxiv.org/abs/2003.06754) / [project](https://arxiv.org/abs/2003.06754/) / CVPR 2020 / MotionNet  
• FIERY: Future Instance Prediction in Bird's-Eye View from Surround Monocular Cameras / [paper](https://arxiv.org/abs/2104.10490) / [project](https://github.com/wayveai/fiery/) / ICCV 2021 / FIERY  
• BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving / [paper](https://arxiv.org/abs/2205.09743) / [project](https://github.com/zhangyp15/BEVerse/) / ITSC 2023 / BEVerse  
• BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection / [paper](https://arxiv.org/abs/2203.17054) / [project](https://github.com/ChenControl/BEVDet4D/) / arXiv / BEVDet4D  
• Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection / [paper](https://arxiv.org/abs/2303.11926) / [project](https://github.com/exiawsh/StreamPETR/) / ICCV 2023 / StreamPETR  
• Towards Efficient 3D Object Detection in Bird's-Eye-View Space for Autonomous Driving: A Convolutional-Only Approach / [paper](https://arxiv.org/abs/2312.00633) / ITSC 2023 / BEVENet  
### Multi-stage fusion methods.
• Enabling spatio-temporal aggregation in Birds-Eye-View Vehicle Estimation / [paper](https://ieeexplore.ieee.org/abstract/document/9561169) / [project](https://github.com/HCIS-Lab/GaussianLSS/) / ICRA 2021 / STA-ST  
• ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning / [paper](https://arxiv.org/abs/2207.07601) / [project](https://github.com/OpenDriveLab/ST-P3/) / ECCV 2022 / ST-P3  
• Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection / [paper](https://arxiv.org/abs/2210.02443) / [project](https://github.com/Divadi/SOLOFusion/) / CVPR 2025 / SOLOFusion  
• Fast-BEV: A Fast and Strong Bird's-Eye View Perception Baseline / [paper](https://arxiv.org/abs/2301.12511) / [project](https://github.com/Sense-GVT/Fast-BEV/) / TPAMI 2024 / Fast-BEV  
• BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers / [paper](https://arxiv.org/abs/2203.17270) / [project](https://github.com/fundamentalvision/BEVFormer/) / ECCV 2022 / BEVFormer  
• PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images / [paper](https://arxiv.org/abs/2206.01256) / [project](https://github.com/megvii-research/PETR/) / ICCV 2022 / PETRv2  
• UniFusion: Unified Multi-view Fusion Transformer for Spatial-Temporal Representation in Bird’s-Eye-View / [paper](https://ieeexplore.ieee.org/document/10376774) / [project](https://github.com/cfzd/UniFusion/) / ICCV 2023 / UniFusion  
• Monocular 3D Object Detection with Depth from Motion / [paper](https://arxiv.org/abs/2207.12988) / [project](https://github.com/Tai-Wang/Depth-from-Motion/) / ECCV 2022 / DfM  
• DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking / [paper](https://arxiv.org/abs/2303.16628) / [project](https://github.com/OpenRobotLab/DORT/) / arXiv / DORT  